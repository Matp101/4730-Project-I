{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# load the dataset\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m mnist\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mprogressbar\u001b[39;00m \u001b[39mimport\u001b[39;00m progressbar\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from progressbar import progressbar\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from itertools import product\n",
    "\n",
    "from layers.Conv2D import Conv2D\n",
    "from layers.Pooling import Pooling\n",
    "from layers.Dense import Dense\n",
    "from layers.Flatten import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "(train_x, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "# scale the data\n",
    "train_x, test_X = train_x / 255.0, test_X / 255.0\n",
    "\n",
    "\n",
    "# reduce the size of the dataset\n",
    "train_x, test_X = train_x[:100], test_X[:10]\n",
    "train_y, test_y = train_y[:100], test_y[:10]\n",
    "\n",
    "# need the fourth dimension to represent the number of channels\n",
    "train_x = train_x.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print('Train: X=%s, y=%s' % (train_x.shape, train_y.shape))\n",
    "print('Test: X=%s, y=%s' % (test_X.shape, test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = []\n",
    "model.append(Conv2D(32, 2, 1, 1))\n",
    "model.append(Pooling(2, 2, 'max'))\n",
    "model.append(Flatten())\n",
    "dims = train_x[0]\n",
    "for layer in model:\n",
    "    # print(dims.shape)\n",
    "    dims = layer.forward(dims)\n",
    "# print(dims.shape)\n",
    "model.append(Dense(dims.shape[0], 128))\n",
    "model.append(Dense(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    # forward pass on a single image\n",
    "    for layer in model:\n",
    "        X = layer.forward(X)\n",
    "    return X\n",
    "\n",
    "def predict_batch(X, model) -> np.ndarray:\n",
    "    # forward pass on a batch of images\n",
    "    #y_pred = np.array([predict(X, model)])\n",
    "    with mp.Pool(mp.cpu_count()) as p:\n",
    "        ps = [p.apply_async(predict, args=(x,model,)) for x in X]\n",
    "    y_pred = [p.get() for p in progressbar(ps, prefix='predicting ')]\n",
    "\n",
    "def train(X, y, model, lr=0.01):\n",
    "    # forward pass\n",
    "    y_pred = predict_batch(X, model)\n",
    "    # calculate loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print('loss: %f' % loss)\n",
    "\n",
    "    # backward pass\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    for layer in reversed(model):\n",
    "        grad_y_pred = layer.backward(grad_y_pred, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "train(train_X, train_y, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69014978dff4cd2ac6ff126ac73b819d88be721f7106444d875d4f83481673be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
