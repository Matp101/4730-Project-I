{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from progressbar import progressbar\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from itertools import product\n",
    "\n",
    "from layers.Conv2D import Conv2D\n",
    "from layers.Pooling import Pooling\n",
    "from layers.Dense import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(10000, 28, 28), y=(10000,)\n",
      "Test: X=(1000, 28, 28), y=(1000,)\n"
     ]
    }
   ],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "train_X, test_X = train_X / 255.0, test_X / 255.0\n",
    "\n",
    "train_X, test_X = train_X[:10000], test_X[:1000]\n",
    "train_y, test_y = train_y[:10000], test_y[:1000]\n",
    "\n",
    "print('Train: X=%s, y=%s' % (train_X.shape, train_y.shape))\n",
    "print('Test: X=%s, y=%s' % (test_X.shape, test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "\n",
    "model = [\n",
    "    Conv2D(32, 2, 1, 1),\n",
    "    Pooling(2, 2, 'max'),\n",
    "    Dense(32*14*14, 100),\n",
    "    Dense(100, 10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'product' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m         grad_y_pred \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mbackward(grad_y_pred, lr)\n\u001b[1;32m     19\u001b[0m \u001b[39m# train the model\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m train(train_X, train_y)\n",
      "Cell \u001b[0;32mIn [6], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(X, y, lr)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(X, y, lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m):\n\u001b[0;32m---> 11\u001b[0m     y_pred \u001b[39m=\u001b[39m predict(X)\n\u001b[1;32m     12\u001b[0m     loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msquare(y_pred \u001b[39m-\u001b[39m y)\u001b[39m.\u001b[39msum()\n\u001b[1;32m     13\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mloss: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m loss)\n",
      "Cell \u001b[0;32mIn [6], line 3\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(X):\n\u001b[1;32m      2\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model:\n\u001b[0;32m----> 3\u001b[0m         X \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mforward(X)\n\u001b[1;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/X/classes/4730-Project-I/layers/Conv2D.py:25\u001b[0m, in \u001b[0;36mConv2D.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     23\u001b[0m Y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((h_out, w_out, d_out))\n\u001b[1;32m     24\u001b[0m \u001b[39m#dot product of the filter and the image at each stride\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfor\u001b[39;00m i, j, k \u001b[39min\u001b[39;00m product(\u001b[39mrange\u001b[39m(h_out), \u001b[39mrange\u001b[39m(w_out), \u001b[39mrange\u001b[39m(d_out)):\n\u001b[1;32m     26\u001b[0m     \u001b[39m#dot product of the filter and the image at each stride\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     temp \u001b[39m=\u001b[39m X[i:i\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspatial_extent, j:j\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspatial_extent, :] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilters[k, :, :]\n\u001b[1;32m     28\u001b[0m     product \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(temp)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'product' referenced before assignment"
     ]
    }
   ],
   "source": [
    "def predict(X):\n",
    "    for layer in model:\n",
    "        X = layer.forward(X)\n",
    "    return X\n",
    "\n",
    "def predict_batch(X):\n",
    "    with mp.Pool() as pool:\n",
    "        return pool.map(predict, X)\n",
    "\n",
    "def train(X, y, lr=0.01):\n",
    "    y_pred = predict(X)\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print('loss: %f' % loss)\n",
    "\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    for layer in reversed(model):\n",
    "        grad_y_pred = layer.backward(grad_y_pred, lr)\n",
    "\n",
    "# train the model\n",
    "train(train_X, train_y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2bda97dbc5b7182aa045b7303d96374423bac724f04ce58734e0c5059b215181"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
