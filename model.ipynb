{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from progressbar import progressbar\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from itertools import product\n",
    "\n",
    "from layers.Conv2D import Conv2D\n",
    "from layers.Pooling import Pooling\n",
    "from layers.Dense import Dense\n",
    "from layers.Flatten import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(10000, 28, 28), y=(10000,)\n",
      "Test: X=(1000, 28, 28), y=(1000,)\n"
     ]
    }
   ],
   "source": [
    "# import the data\n",
    "(train_x, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "# scale the data\n",
    "train_x, test_X = train_x / 255.0, test_X / 255.0\n",
    "\n",
    "\n",
    "# reduce the size of the dataset\n",
    "train_x, test_X = train_x[:100], test_X[:10]\n",
    "train_y, test_y = train_y[:100], test_y[:10]\n",
    "\n",
    "# need the fourth dimension to represent the number of channels\n",
    "train_x = train_x.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print('Train: X=%s, y=%s' % (train_x.shape, train_y.shape))\n",
    "print('Test: X=%s, y=%s' % (test_X.shape, test_y.shape))\n",
    "\n",
    "return train_x, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "\n",
    "model = []\n",
    "model.append(Conv2D(32, 2, 1, 1))\n",
    "model.append(Pooling(2, 2, 'max'))\n",
    "model.append(Flatten())\n",
    "dims = train_x[0]\n",
    "for layer in model:\n",
    "    # print(dims.shape)\n",
    "    dims = layer.forward(dims)\n",
    "# print(dims.shape)\n",
    "model.append(Dense(dims.shape[0], 128))\n",
    "model.append(Dense(128, 10))\n",
    "return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'product' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m         grad_y_pred \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mbackward(grad_y_pred, lr)\n\u001b[1;32m     19\u001b[0m \u001b[39m# train the model\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m train(train_X, train_y)\n",
      "Cell \u001b[0;32mIn [6], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(X, y, lr)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(X, y, lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m):\n\u001b[0;32m---> 11\u001b[0m     y_pred \u001b[39m=\u001b[39m predict(X)\n\u001b[1;32m     12\u001b[0m     loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msquare(y_pred \u001b[39m-\u001b[39m y)\u001b[39m.\u001b[39msum()\n\u001b[1;32m     13\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mloss: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m loss)\n",
      "Cell \u001b[0;32mIn [6], line 3\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(X):\n\u001b[1;32m      2\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model:\n\u001b[0;32m----> 3\u001b[0m         X \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mforward(X)\n\u001b[1;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/X/classes/4730-Project-I/layers/Conv2D.py:25\u001b[0m, in \u001b[0;36mConv2D.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     23\u001b[0m Y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((h_out, w_out, d_out))\n\u001b[1;32m     24\u001b[0m \u001b[39m#dot product of the filter and the image at each stride\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfor\u001b[39;00m i, j, k \u001b[39min\u001b[39;00m product(\u001b[39mrange\u001b[39m(h_out), \u001b[39mrange\u001b[39m(w_out), \u001b[39mrange\u001b[39m(d_out)):\n\u001b[1;32m     26\u001b[0m     \u001b[39m#dot product of the filter and the image at each stride\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     temp \u001b[39m=\u001b[39m X[i:i\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspatial_extent, j:j\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspatial_extent, :] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilters[k, :, :]\n\u001b[1;32m     28\u001b[0m     product \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(temp)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'product' referenced before assignment"
     ]
    }
   ],
   "source": [
    "def predict(X):\n",
    "    # forward pass on a single image\n",
    "    for layer in model:\n",
    "        X = layer.forward(X)\n",
    "    return X\n",
    "\n",
    "def predict_batch(X, model) -> np.ndarray:\n",
    "    # forward pass on a batch of images\n",
    "    #y_pred = np.array([predict(X, model)])\n",
    "    with mp.Pool(mp.cpu_count()) as p:\n",
    "        ps = [p.apply_async(predict, args=(x,model,)) for x in X]\n",
    "    y_pred = [p.get() for p in progressbar(ps, prefix='predicting ')]\n",
    "\n",
    "def train(X, y, model, lr=0.01):\n",
    "    # forward pass\n",
    "    y_pred = predict_batch(X, model)\n",
    "    # calculate loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print('loss: %f' % loss)\n",
    "\n",
    "    # backward pass\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    for layer in reversed(model):\n",
    "        grad_y_pred = layer.backward(grad_y_pred, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "train(train_X, train_y, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2bda97dbc5b7182aa045b7303d96374423bac724f04ce58734e0c5059b215181"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
