{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-16 06:28:53.316300: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "#from progressbar import ProgressBar as progressbar\n",
    "from progressbar import *\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from itertools import product\n",
    "import sys\n",
    "\n",
    "from layers.Conv2D import Conv2D\n",
    "from layers.Pooling import Pooling\n",
    "from layers.Dense import Dense\n",
    "from layers.Flatten import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(1000, 28, 28, 1), y=(1000,)\n",
      "Test: X=(1000, 28, 28, 1), y=(1000,)\n"
     ]
    }
   ],
   "source": [
    "# import the data\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "# scale the data\n",
    "train_X, test_X = train_X / 255.0, test_X / 255.0\n",
    "\n",
    "\n",
    "# reduce the size of the dataset\n",
    "train_X, test_X = train_X[:1000], test_X[:1000]\n",
    "train_y, test_y = train_y[:1000], test_y[:1000]\n",
    "\n",
    "# need the fourth dimension to represent the number of channels\n",
    "train_X = train_X.reshape(-1, 28, 28, 1)\n",
    "test_X = test_X.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print('Train: X=%s, y=%s' % (train_X.shape, train_y.shape))\n",
    "print('Test: X=%s, y=%s' % (test_X.shape, test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = []\n",
    "\n",
    "model.append(Conv2D(32, 2, 1, 1))\n",
    "model.append(Pooling(2, 2, 'max'))\n",
    "model.append(Flatten())\n",
    "\n",
    "# determine the number of input features by running one forward pass on one image\n",
    "dims = train_X[0]\n",
    "dims = dims.reshape(1, *dims.shape)\n",
    "for layer in model:\n",
    "    dims = layer.forward(dims)\n",
    "\n",
    "\n",
    "model.append(Dense(np.prod(dims.shape[1]), 10))\n",
    "#model.append(Dense(np.prod(dims.shape[1]), 128))\n",
    "#model.append(Dense(128, 10))\n",
    "\n",
    "for layer in model[3:]:\n",
    "    dims = layer.forward(dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, model):\n",
    "    # forward pass on a single image\n",
    "    #plot_image(X[0])            \n",
    "    for layer in model:\n",
    "        X = layer.forward(X)\n",
    "\n",
    "        #print('layer %s, X %s' % (layer.name, X.shape))\n",
    "        #plot_image(X[0, :, :, 0, 0])            \n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def train(X, y, model, lr=0.01, epochs=10):\n",
    "\n",
    "    # need to make epochs work\n",
    "    # need to do forward passes chunks of mp.cpu_count() images at a time\n",
    "    # when each forward pass is done, do a backward pass on the same chunk of images\n",
    "    chunksize = 100\n",
    "    # create a one-hot vector of y\n",
    "    #y = np.eye(10)[y]\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    widgets = [FormatLabel(''), ' Training: ', Percentage(), ' ', SimpleProgress(), ' ', Bar(), ' ', ETA(), ' ', FormatLabel(''), ' ', FormatLabel('')]\n",
    "    for epoch in range(epochs):\n",
    "        widgets[0] = FormatLabel('(epoch {:.0f})'.format(epoch))\n",
    "        p = ProgressBar(max_value=X.shape[0], widgets=widgets, redirect_stdout=True)\n",
    "        # break into chunks of at most mp.cpu_count() images\n",
    "        for i in range(0, len(X), chunksize):\n",
    "            loss = 0\n",
    "            accuracy = 0\n",
    "            # forward pass\n",
    "            y_pred = predict(X[i:min(X.shape[0], i+chunksize)], model)\n",
    "\n",
    "            \n",
    "            # gradient\n",
    "            #cross_entropy loss\n",
    "            for j in range(chunksize):\n",
    "                for d in range(y_pred.shape[2]):\n",
    "                    loss += -np.log(y_pred[j, y[j+i], d])\n",
    "                    accuracy += 1 if np.argmax(y_pred[j, :, d]) == y[j+i] else 0\n",
    "            loss /= chunksize\n",
    "            accuracy /= chunksize * 100\n",
    "            widgets[10] = FormatLabel('(loss: {:.16f}, '.format(loss))\n",
    "            widgets[12] = FormatLabel('accuracy: {:.4f})'.format(accuracy))\n",
    "\n",
    "            grad = np.zeros(y_pred.shape)\n",
    "            for j in range(chunksize):\n",
    "                grad[y[j+i]] = -1 / y_pred[j, y[j+i]]\n",
    "\n",
    "            # backward pass\n",
    "            for layer in reversed(model):\n",
    "                grad = layer.backward(grad, lr)\n",
    "            \n",
    "            p.update(i)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        p.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train(train_X, train_y, model)\n",
      "Cell \u001b[0;32mIn [5], line 48\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(X, y, model, lr, epochs)\u001b[0m\n\u001b[1;32m     46\u001b[0m grad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(y_pred\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     47\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(chunksize):\n\u001b[0;32m---> 48\u001b[0m     grad[y[j\u001b[39m+\u001b[39;49mi]] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39m/\u001b[39m y_pred[j, y[j\u001b[39m+\u001b[39mi]]\n\u001b[1;32m     50\u001b[0m \u001b[39m# backward pass\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(model):\n",
      "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "train(train_X, train_y, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
