{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 of project: Data Wrangling\n",
    "\n",
    "- We will be using the mnist dataset for this project.\n",
    "- The first iteration will use pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by loading the dataset, pre-split and processed by keras.datsets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "print('Train: X=%s, y=%s' % (train_X.shape, train_y.shape))\n",
    "print('Test: X=%s, y=%s' % (test_X.shape, test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of reading, we also generate an image to display the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(train_X[i], cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pooling layer pads the inputs of the images, and takes the max or mean value of the pixels in the window. This is done to reduce the size of the image, and to reduce the number of parameters in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "# pooling the dataset\n",
    "# mode = max, mean\n",
    "def pooling_layer2D(X, spatial_extent=2, stride=2, mode='max'):\n",
    "    X = np.asarray(X)\n",
    "    h, w = X.shape\n",
    "    h_out = int((h - spatial_extent) / stride) + 1\n",
    "    w_out = int((w - spatial_extent) / stride) + 1\n",
    "    #get the max/mean value in the spatial extent stride by stride\n",
    "    Y = np.zeros((h_out, w_out))\n",
    "    for i, j in product(range(h_out), range(w_out)):\n",
    "        if mode == 'max':\n",
    "            Y[i, j] = np.max(X[i * stride:i * stride + spatial_extent, j * stride:j * stride + spatial_extent])\n",
    "        elif mode == 'mean':\n",
    "            Y[i, j] = np.mean(X[i * stride:i * stride + spatial_extent, j * stride:j * stride + spatial_extent])\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering is also done with a sliding window, similarly to pooling, except each output pixel is the result of a dot product between the filter and the window of pixels for each stride position in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "# conv the dataset\n",
    "#num_filters = powers of 2\n",
    "#rand = [0,1)\n",
    "def filter_gen(spatial_extent, num_filters):\n",
    "    return np.random.rand(num_filters, spatial_extent, spatial_extent) -0.5\n",
    "\n",
    "def kfilter_scan(X, num_filters, spatial_extent, stride, zero_padding):\n",
    "    X = np.asarray(X)\n",
    "    h, w = X.shape\n",
    "    #add zero padding\n",
    "    if zero_padding:\n",
    "        X = np.pad(X, spatial_extent // 2)\n",
    "    w_out = int((w - spatial_extent + (2*zero_padding)) / stride) + 1\n",
    "    h_out = int((h - spatial_extent + (2*zero_padding)) / stride) + 1\n",
    "\n",
    "    filters = filter_gen(spatial_extent, num_filters)\n",
    "    #get the max/mean value in the spatial extent stride by stride\n",
    "    Y = np.zeros((h_out, w_out))\n",
    "    #dot product of the filter and the image at each stride\n",
    "    for i, j in product(range(h_out), range(w_out)):\n",
    "        temp = X[i * stride:i * stride + spatial_extent, j * stride:j * stride + spatial_extent]\n",
    "        Y[i,j] = np.dot(temp.flatten(), filters[0].flatten())      \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a relu activation layer, to remove any negative values from the output of the convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_layer(image):\n",
    "    h, w = image.shape\n",
    "    new_image = np.zeros((h, w))\n",
    "    for  i, j in product(range(h), range(w)):\n",
    "        new_image[i,j] = relu(image[i,j])\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data, as it stands, after running it through pooling and convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(train_X[i], cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "\n",
    "for i in range(9):\n",
    "    poollayer = pooling_layer2D(train_X[i], spatial_extent=2, stride=2, mode='max')\n",
    "    filtered = kfilter_scan(poollayer, num_filters=2, spatial_extent=4, stride=2, zero_padding=1)\n",
    "    relued = relu_layer(filtered)\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(relued, cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will add a fully connected layer, to reduce the number of parameters in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dense(input, weights, bias):\n",
    "    return np.dot(input, weights) + bias\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def softmax_layer(image):\n",
    "    h, w = image.shape\n",
    "    new_image = np.zeros((h, w))\n",
    "    for  i, j in product(range(h), range(w)):\n",
    "        new_image[i,j] = softmax(image[i,j])\n",
    "    return new_image\n",
    "\n",
    "def cnn(X, weights, bias):\n",
    "    poollayer = pooling_layer2D(X, spatial_extent=2, stride=2, mode='max')\n",
    "    filtered = kfilter_scan(poollayer, num_filters=2, spatial_extent=4, stride=2, zero_padding=1)\n",
    "    relued = relu_layer(filtered)\n",
    "    dense = Dense(relued, weights, bias)\n",
    "    return softmax_layer(dense)\n",
    "\n",
    "def cnn_loss(X, y, weights, bias):\n",
    "    pred = cnn(X, weights, bias)\n",
    "    return -np.log(pred[y])\n",
    "\n",
    "def cnn_loss_grad(X, y, weights, bias):\n",
    "    pred = cnn(X, weights, bias)\n",
    "    pred[y] -= 1\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, we will add a dropout layer, to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2bda97dbc5b7182aa045b7303d96374423bac724f04ce58734e0c5059b215181"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
